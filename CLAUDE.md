# CLAUDE.md â€” nanoGPT_RH Quick Reference

> **Ğ§Ğ¸Ñ‚Ğ°Ğ¹ ÑÑ‚Ğ¾ ĞŸĞ•Ğ Ğ’Ğ«Ğœ Ğ¿Ñ€Ğ¸ Ğ²Ñ…Ğ¾Ğ´Ğµ Ğ² Ğ¿Ñ€Ğ¾ĞµĞºÑ‚!**
> Ğ—Ğ´ĞµÑÑŒ Ğ²ÑĞµ Ğ¿ÑƒÑ‚Ğ¸, ĞºĞ¾Ğ½Ğ²ĞµĞ½Ñ†Ğ¸Ğ¸, workflow â€” Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ·Ğ°Ğ½Ğ¾Ğ²Ğ¾.

---

## ğŸ¯ QUICK REFERENCE (Jan 2026)

### Current Status
```
âœ… E4 COMPLETE â€” ID-Detox works!
â­ Best Model: checkpoints/E4_s7_best.pt (NLL=0.1942)
ğŸ“ Next: E5 (slot specialization) OR symbolic extraction
```

### Key Paths (Ğ—ĞĞŸĞĞœĞĞ˜!)
```
INPUT:
  data/continuous_2M/train.pt    # (7035, 256) training data
  data/continuous_2M/val.pt      # (781, 256) validation data

CODE:
  src/train_mdn_postfix.py       # â­ Main training script
  src/eval_mdn.py                # Evaluation
  src/diagnose_memory_postfix.py # Diagnostics

OUTPUT:
  out/                           # Temporary (gitignored)
  checkpoints/                   # Final models (in git)
  results/                       # Diagnostics output (in git)

DOCS:
  docs/PROJECT_MAP.md            # â­ Main project map
  docs/E4_SPEC.md                # E4 specification
  docs/runpod_specs.md           # GPU comparison
```

---

## ğŸ”„ EXPERIMENT WORKFLOW

### Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ° (E5, E6, etc.)

**Ğ¨Ğ°Ğ³ 1: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ**
```bash
mkdir -p out/E5_experiment_name
```

**Ğ¨Ğ°Ğ³ 2: Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºÑƒ**
```bash
python src/train_mdn_postfix.py \
  --data-dir data/continuous_2M \
  --out-dir out/E5_experiment_name \
  --seed 7 \
  [Ğ½Ğ¾Ğ²Ñ‹Ğµ Ñ„Ğ»Ğ°Ğ³Ğ¸] \
  --batch-size 512 --use-amp
```

**Ğ¨Ğ°Ğ³ 3: ĞŸĞ¾ÑĞ»Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ â€” Ñ€Ğ°ÑĞºĞ»Ğ°Ğ´Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹**
```bash
# Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ â†’ checkpoints/
cp out/E5_experiment_name/best.pt checkpoints/E5_best.pt

# Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ° â†’ results/
mkdir -p results/E5
python src/diagnose_memory_postfix.py \
  --ckpt checkpoints/E5_best.pt \
  --data-dir data/continuous_2M \
  --output-dir results/E5

# ĞĞ±Ğ½Ğ¾Ğ²Ğ¸ docs/PROJECT_MAP.md Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸!
```

**Ğ¨Ğ°Ğ³ 4: Cleanup Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²**
```bash
# out/ Ğ² gitignore â€” Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑƒĞ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ Ğ¸Ğ»Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾
rm -rf out/E5_experiment_name/ckpt_*.pt  # ÑƒĞ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ
```

---

## ğŸ“ I/O CONVENTIONS

### Naming Rules
```
Checkpoints:  E{N}_{description}_best.pt
              E4_s7_best.pt, E5_ortho_best.pt

Results:      results/E{N}/
              results/E4_s7/postfix_diagnostics.jsonl

Logs:         out/E{N}_{name}/train.log (temporary)
```

### Input Paths (ĞĞ˜ĞšĞĞ“Ğ”Ğ Ğ½Ğµ Ğ¼ĞµĞ½ÑĞ¹!)
```python
DATA_DIR = "data/continuous_2M"
TRAIN_PATH = "data/continuous_2M/train.pt"  # (7035, 256)
VAL_PATH = "data/continuous_2M/val.pt"      # (781, 256)
```

### Output Paths
```python
# Temporary (during training):
OUT_DIR = f"out/{experiment_name}"

# Permanent (after training):
CHECKPOINT = f"checkpoints/{experiment_name}_best.pt"
RESULTS = f"results/{experiment_name}/"
```

---

## ğŸ“ LOGGING RULES (ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§ĞĞ!)

### ĞŸÑ€Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞµ ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ:

**Ğ’ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ:**
- GPU name, VRAM
- batch_size
- Experiment config (flags)

**ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ eval:**
```
Step 1000/20000 | val_nll=0.358 (best=0.358) | 5.8 steps/s | ETA: 55m | elapsed: 2.9m
```

**Ğ’ ĞºĞ¾Ğ½Ñ†Ğµ:**
- Total time, steps/sec
- Best NLL achieved
- Cost estimate ($/hr Ã— time)

---

## ğŸ“‹ ĞŸĞĞ¡Ğ›Ğ• ĞšĞĞ–Ğ”ĞĞ“Ğ Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ˜ĞœĞ•ĞĞ¢Ğ

### Checklist:
- [ ] Ğ¡ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ `best.pt` Ğ² `checkpoints/`
- [ ] Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºÑƒ Ğ² `results/`
- [ ] ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ `docs/PROJECT_MAP.md`:
  - Experiments Timeline
  - E{N} Results table
  - Key Insights Log
- [ ] Commit & push

---

## ğŸ—ï¸ Repository Structure

```
nanoGpt_RH/
â”‚
â”œâ”€â”€ ğŸ“ src/                      # MAIN CODE
â”‚   â”œâ”€â”€ train_mdn.py             # Base SpacingMDN (MDNConfig)
â”‚   â”œâ”€â”€ train_mdn_postfix.py     # â­ E4 training (ID-Detox, aux-loss)
â”‚   â”œâ”€â”€ train_mdn_memory.py      # PREFIX memory (deprecated)
â”‚   â”œâ”€â”€ eval_mdn.py              # Evaluation (NLL, CRPS, PIT)
â”‚   â”œâ”€â”€ diagnose_memory.py       # PREFIX diagnostics
â”‚   â””â”€â”€ diagnose_memory_postfix.py # â­ POSTFIX diagnostics (A-K)
â”‚
â”œâ”€â”€ ğŸ“ scripts/                  # UTILITIES
â”‚   â”œâ”€â”€ prepare_continuous_2M.py # Unfolding zeros â†’ spacings
â”‚   â”œâ”€â”€ prepare_zeros.py         # Raw zeros processing
â”‚   â”œâ”€â”€ prepare_primes.py        # Prime gaps dataset
â”‚   â””â”€â”€ runpod_setup.sh          # RunPod setup script
â”‚
â”œâ”€â”€ ğŸ“ checkpoints/              # TRAINED MODELS (Git LFS)
â”‚   â”œâ”€â”€ E0_baseline_best.pt      # SpacingMDN no memory
â”‚   â”œâ”€â”€ E1_prefix_best.pt        # PREFIX (decorative)
â”‚   â”œâ”€â”€ E2_prefix_best.pt        # PREFIX (seed variance)
â”‚   â”œâ”€â”€ E3_postfix_s1337_best.pt # POSTFIX (ID-crutch)
â”‚   â”œâ”€â”€ E4_s7_best.pt            # â­ BEST! NLL=0.1942
â”‚   â””â”€â”€ E4_s1337_best.pt         # E4 (stuck seed)
â”‚
â”œâ”€â”€ ğŸ“ data/                     # DATASET
â”‚   â””â”€â”€ continuous_2M/           # Main dataset
â”‚       â”œâ”€â”€ train.pt             # (7035, 256)
â”‚       â”œâ”€â”€ val.pt               # (781, 256)
â”‚       â””â”€â”€ meta.pt
â”‚
â”œâ”€â”€ ğŸ“ docs/                     # DOCUMENTATION
â”‚   â”œâ”€â”€ PROJECT_MAP.md           # â­ MAIN PROJECT MAP
â”‚   â”œâ”€â”€ E4_SPEC.md               # E4 specification
â”‚   â””â”€â”€ runpod_specs.md          # GPU comparison
â”‚
â”œâ”€â”€ ğŸ“ results/                  # DIAGNOSTICS OUTPUT
â”‚   â””â”€â”€ E4_s7/
â”‚       â”œâ”€â”€ postfix_diagnostics.jsonl
â”‚       â””â”€â”€ postfix_diagnostics.png
â”‚
â”œâ”€â”€ ğŸ“ out/                      # TEMPORARY (gitignored)
â”‚
â””â”€â”€ ğŸ“ archive/                  # OLD CODE (gitignored)
```

---

## ğŸ–¥ï¸ RunPod Quick Start

### Package & Send
```bash
tar czf runpod_package.tar.gz \
  src/train_mdn.py src/train_mdn_postfix.py \
  src/eval_mdn.py src/diagnose_memory_postfix.py \
  scripts/runpod_setup.sh data/continuous_2M

runpodctl send runpod_package.tar.gz
```

### On Pod
```bash
runpodctl receive <CODE> && tar xzf runpod_package.tar.gz

# Training
python src/train_mdn_postfix.py \
  --data-dir data/continuous_2M \
  --out-dir out/E5_experiment \
  --seed 7 \
  --slot-id-mode permute_per_batch \
  --use-aux-loss \
  --early-stop --patience 800 \
  --batch-size 512 --use-amp
```

### Download Results
```bash
# On pod:
tar czf results.tar.gz out/E5_experiment/ && runpodctl send results.tar.gz

# On Mac:
runpodctl receive <CODE>
tar xzf results.tar.gz
```

### GPU Selection
```
DEFAULT: L40S @ $0.86/hr (48GB, ML-optimized, high availability)
BUDGET:  A40 @ $0.40/hr (48GB, best $/perf)
FAST:    H100 @ $2.69/hr (80GB, 2.5x speed)
```

---

## âš™ï¸ E4 Training Flags Reference

```bash
python src/train_mdn_postfix.py \
  --data-dir data/continuous_2M \      # INPUT: always this!
  --out-dir out/experiment_name \      # OUTPUT: temporary
  --seed 7 \                           # Seed (7 worked best)
  --slot-id-mode permute_per_batch \   # ID-detox (E4)
  --content-mode normal \              # or zeroed
  --use-aux-loss \                     # Q3-proxy supervision
  --early-stop --patience 800 \        # Early stopping
  --batch-size 512 \                   # 512 for 48GB GPU
  --use-amp                            # Mixed precision
```

---

## ğŸ”¬ Diagnostics Metrics

### A-K Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ² diagnose_memory_postfix.py:
```
A) Ablation Î”      â€” Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ»Ğ¾Ñ‚Ğ° (Ñ†ĞµĞ»ÑŒ: >0.02)
B) Slot Similarity â€” ĞºĞ¾ÑĞ¸Ğ½ÑƒÑĞ½Ğ¾Ğµ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ (Ñ†ĞµĞ»ÑŒ: <0.5)
C) Grad Correlationâ€” ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ñ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² (Ñ†ĞµĞ»ÑŒ: <0.7)
D) Readout Weights â€” Ğ²ĞµÑĞ° Ñ‡Ñ‚ĞµĞ½Ğ¸Ñ (Ñ†ĞµĞ»ÑŒ: uniform)
E) Effect Entropy  â€” ÑĞ½Ñ‚Ñ€Ğ¾Ğ¿Ğ¸Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ° (Ñ†ĞµĞ»ÑŒ: >1.5)
F) Slot Norms      â€” Ğ½Ğ¾Ñ€Ğ¼Ñ‹ ÑĞ»Ğ¾Ñ‚Ğ¾Ğ²
G) Rollout Drift   â€” Ñ€Ğ¾ÑÑ‚ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ (Ñ†ĞµĞ»ÑŒ: slope<0.5)
H) Cross-Block CV  â€” distribution shift (Ñ†ĞµĞ»ÑŒ: <0.3)
I) Attention CoM   â€” center of mass (Ñ†ĞµĞ»ÑŒ: std>10)
J) Permutation Inc â€” ID-reliance (Ñ†ĞµĞ»ÑŒ: <10%)
K) Gradient Rank   â€” effective rank (Ñ†ĞµĞ»ÑŒ: >50%)
```

---

## ğŸ“Š Experiments History

| ID | Architecture | Best NLL | Key Result |
|----|--------------|----------|------------|
| E0 | Baseline MDN | -0.25 | No memory |
| E1 | PREFIX Memory | -0.38 | Memory decorative |
| E2 | PREFIX Memory | -0.38 | Seed variance |
| E3 | POSTFIX Memory | 0.304 | ID-crutch detected |
| **E4** | **POSTFIX+ID-Detox** | **0.1942** | **ID-Detox works!** |

---

## âŒ COMMON MISTAKES (Ğ½Ğµ Ğ´ĞµĞ»Ğ°Ğ¹!)

1. **ĞĞµ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ğ¹ Ğ¸Ğ· root Ğ±ĞµĞ· ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¿ÑƒÑ‚ĞµĞ¹!**
   ```bash
   # WRONG:
   python train_mdn_postfix.py

   # RIGHT:
   python src/train_mdn_postfix.py --data-dir data/continuous_2M
   ```

2. **ĞĞµ Ğ·Ğ°Ğ±Ñ‹Ğ²Ğ°Ğ¹ --out-dir!**
   - Ğ‘ĞµĞ· Ğ½ĞµĞ³Ğ¾ output Ğ¿Ğ¾Ğ¹Ğ´ĞµÑ‚ Ğ² ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğµ Ğ¼ĞµÑÑ‚Ğ¾

3. **ĞĞµ ĞºĞ¾Ğ¼Ğ¼Ğ¸Ñ‚ÑŒ out/ !**
   - Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ checkpoints/ Ğ¸ results/

4. **ĞŸĞ¾ÑĞ»Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ° â€” Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸ docs/PROJECT_MAP.md!**

---

## ğŸ“ Project Overview

**nanoGPT_RH** â€” Neural telescope for Riemann Hypothesis spectral analysis.

**Goal:** Train transformer on 2M unfolded zeta zeros to:
1. Learn GUE-like spacing distribution
2. Extract operator/kernel via attention
3. Compare with Q3 formal structures

**Architecture:** SpacingMDN + POSTFIX Memory Bank
- Memory slots AFTER data (bottleneck readout)
- ID-Detox prevents slot-ID cheating
- Q3-proxy aux loss for supervision

**Data:** Unfolded spacings with mean â‰ˆ 1
```
s_n = Î”_n * log(Î³_n) / (2Ï€)
```

---

*Last updated: 2026-01-01*
