# CLAUDE.md ‚Äî nanoGPT_RH Quick Reference

> **–ß–∏—Ç–∞–π —ç—Ç–æ –ü–ï–†–í–´–ú –ø—Ä–∏ –≤—Ö–æ–¥–µ –≤ –ø—Ä–æ–µ–∫—Ç!**
> –ó–¥–µ—Å—å –≤—Å–µ –ø—É—Ç–∏, –∫–æ–Ω–≤–µ–Ω—Ü–∏–∏, workflow ‚Äî —á—Ç–æ–±—ã –Ω–µ —É—á–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∑–∞–Ω–æ–≤–æ.

---

## üéØ QUICK REFERENCE (Jan 2026)

### Current Status
```
‚úÖ E4 COMPLETE ‚Äî ID-Detox works!
‚≠ê Best Model: checkpoints/E4_s7_best.pt (NLL=0.1942)
üî¨ TESTING: Is œÄ real or bias artifact?
   Model predictions: s‚Çô = 3.1084/(s‚Çã‚ÇÅ+s‚Çã‚ÇÇ+s‚Çã‚ÇÉ) ‚Üê œÄ!
   True values (--target true): s‚Çô = 2.83/(...) ‚Üê NOT œÄ!

   Hypothesis: œÄ = 2.92 √ó 1.062 (model bias creates œÄ!)
üìç Run 5 IN PROGRESS: PySR with --target true (~30 min remaining)
```

### Key Paths (–ó–ê–ü–û–ú–ù–ò!)
```
INPUT:
  data/continuous_500M/train.pt  # ‚≠ê (1.76M, 256) 500M zeros!
  data/continuous_500M/val.pt    # (195K, 256) val_tail
  data/continuous_2M/            # (legacy, 7K windows)

CODE:
  src/train_mdn_postfix.py       # ‚≠ê Main training script
  src/data_loading.py            # üöÄ Streaming DataLoader (gpu-direct/mmap)
  src/eval_mdn.py                # Evaluation
  src/diagnose_memory_postfix.py # Diagnostics

OUTPUT:
  out/                           # Temporary (gitignored)
  checkpoints/                   # Final models (in git)
  results/                       # Diagnostics output (in git)

DOCS:
  docs/PROJECT_MAP.md            # ‚≠ê Main project map
  docs/E4_SPEC.md                # E4 specification
  docs/runpod_specs.md           # GPU comparison
  docs/SPEED_OPTIMIZATION.md     # üöÄ GPU speed tricks (Ampere+)
  docs/OPERATOR_EXTRACTION.md    # üß¨ Masters-inspired operator extraction

FLASH CODE (–Ω–æ–≤–æ–µ):
  src/flash/                     # Flash-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
  src/flash/mdn_flash.py         # Base SpacingMDN + RoPE
  src/flash/memory_mdn_flash.py  # Q3 MemoryMDN
  src/flash/train_memory_q3_flash.py  # Fast training script

FLASH DATA (180M —Ç–æ—á–µ–∫!):
  src/data/flash_residuals/      # Residuals = spacings - 1.0

LMFDB DATA (500M zeros!):
  data/lmfdb_raw/                # Raw .dat files from LMFDB
  data/continuous_500M/          # Processed train.pt, val.pt

LAW-GRADE SCRIPTS (–Ω–æ–≤–æ–µ):
  scripts/prepare_lmfdb_500M.py  # Download & process LMFDB zeros
  scripts/eval_law.py            # Coverage/Width/Rollout eval
  scripts/conformal_calibrate.py # Conformal interval calibration
  scripts/symbolic_distill_quantiles.py  # Q0.1/Q0.5/Q0.9 ‚Üí formulas
  scripts/extract_operator.py    # üß¨ Operator extraction –∏–∑ attention
```

---

## üöÄ –ù–û–í–´–ï –§–ò–ß–ò (Jan 2026)

### 1. Streaming DataLoader (`src/data_loading.py`)
–¢—Ä–∏ —Ä–µ–∂–∏–º–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ 500M+ –Ω—É–ª–µ–π:

```bash
# GPU-direct (–¥–∞–Ω–Ω—ã–µ –Ω–∞ GPU, —Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π)
python src/train_mdn_postfix.py --data-mode gpu-direct ...

# MMap (–ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å –¥–∏—Å–∫–∞, —ç–∫–æ–Ω–æ–º–∏—Ç RAM)
python src/train_mdn_postfix.py --data-mode mmap ...

# Auto (–∞–≤—Ç–æ–≤—ã–±–æ—Ä –ø–æ —Ä–∞–∑–º–µ—Ä—É VRAM)
python src/train_mdn_postfix.py --data-mode auto ...
```

**–ö–ª–∞—Å—Å—ã:** `GPUDirectBatcher`, `MMapBatcher`, `DataLoaderWrapper`

### 2. torch.compile() (20-30% speedup)
–ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è GPU SM‚â•8.0 (Ampere+):

```bash
python src/train_mdn_postfix.py --use-compile ...
```

### 3. W&B Tracking (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã)
–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Weights & Biases:

```bash
# –û–Ω–ª–∞–π–Ω (–Ω—É–∂–µ–Ω wandb login)
python src/train_mdn_postfix.py --use-wandb --wandb-project nanoGPT-RH ...

# –û—Ñ—Ñ–ª–∞–π–Ω
WANDB_MODE=offline python src/train_mdn_postfix.py --use-wandb ...
```

### 4. Operator Extraction (`scripts/extract_operator.py`)
–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ kernel K(s_i, s_j) –∏–∑ attention –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å GUE:

```bash
python scripts/extract_operator.py \
  --checkpoint checkpoints/E4_s7_best.pt \
  --data-dir data/continuous_2M \
  --output-dir results/operator_extraction \
  --run-pysr  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Å–∏–º–≤–æ–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
```

**–í—ã—Ö–æ–¥:**
- `kernel_visualization.png` ‚Äî —Ç—Ä–∏ –≥—Ä–∞—Ñ–∏–∫–∞ attention patterns
- `extraction_results.json` ‚Äî –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å sine kernel, exp decay

### 5. Conformal Calibration (`scripts/conformal_calibrate.py`)
–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ confidence intervals –¥–ª—è —á–µ—Å—Ç–Ω—ã—Ö 90%:

```bash
python scripts/conformal_calibrate.py \
  --ckpt checkpoints/E4_s7_best.pt \
  --data-dir data/continuous_2M \
  --alpha 0.1 \
  --output results/calibrator.json
```

**–í—ã—Ö–æ–¥:** `adjustment_q` ‚Äî –ø–æ–ø—Ä–∞–≤–∫–∞ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤

---

## üì• LMFDB 500M ZEROS DOWNLOAD

### –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö
- **URL:** https://beta.lmfdb.org/data/riemann-zeta-zeros/
- **Precision:** ¬±2^{-102} (David Platt, Turing method verified)
- **Format:** Binary delta-encoded (13 bytes per zero)
- **Total:** 103.8 billion zeros available

### –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –ø—Ä–µ–ø–∞—Ä–∞—Ü–∏—è (–æ–¥–Ω–∞ –∫–æ–º–∞–Ω–¥–∞!)
```bash
python scripts/prepare_lmfdb_500M.py --download --max-zeros 500

# –§–ª–∞–≥–∏:
--download          # –ö–∞—á–∞–µ—Ç –∏–∑ LMFDB —Å cookie human=1
--download-dir      # –ö—É–¥–∞ –∫–∞—á–∞—Ç—å raw .dat (default: data/lmfdb_raw)
--max-zeros N       # –í –ú–ò–õ–õ–ò–û–ù–ê–•! (500=500M, 100=100M, 10=10M)
--output-dir        # –ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å train/val.pt
```

### –ü—Ä–∏–º–µ—Ä—ã:
```bash
# –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç (2M zeros, 1 —Ñ–∞–π–ª)
python scripts/prepare_lmfdb_500M.py --download --max-zeros 2 --output-dir data/test_2M

# –°—Ä–µ–¥–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç (100M zeros)
python scripts/prepare_lmfdb_500M.py --download --max-zeros 100 --output-dir data/continuous_100M

# –ü–æ–ª–Ω—ã–π 500M (239 —Ñ–∞–π–ª–æ–≤)
python scripts/prepare_lmfdb_500M.py --download --max-zeros 500

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
python scripts/prepare_lmfdb_500M.py --input-dir data/lmfdb_raw --max-zeros 100
```

### –§–æ—Ä–º–∞—Ç binary (delta encoding!)
```python
# Block header (32 bytes):
t0, t1, Nt0, Nt1 = struct.unpack('<ddQQ', header)
n_zeros = Nt1 - Nt0

# Zero records (13 bytes each, DELTA encoded):
Z = 0  # Accumulator
for _ in range(n_zeros):
    z1, z2, z3 = struct.unpack('<QIB', record)
    delta = z1 + (z2 << 64) + (z3 << 96)
    Z += delta  # ACCUMULATE!
    gamma = t0 + Z * 2**(-101)
```

### –í–∞–ª–∏–¥–∞—Ü–∏—è spacings
–ü–æ—Å–ª–µ unfolding (Variant B: u(Œ≥) = Œ≥/2œÄ √ó log(Œ≥/2œÄe)):
- Mean ‚âà 1.0 ‚úì
- Std ‚âà 0.41 ‚úì (GUE)
- Autocorr(1) < 0 ‚úì (level repulsion)

### –ì–æ—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç (Jan 2026)
```
data/continuous_500M/
‚îú‚îÄ‚îÄ train.pt   [1,757,812 √ó 256] float32  # 1.8M windows!
‚îú‚îÄ‚îÄ val.pt     [195,312 √ó 256] float32    # 195K windows (val_tail)
‚îî‚îÄ‚îÄ meta.pt    hash=02fc584870ed65ac

Statistics:
  500M zeros processed
  Œ≥ range: [14.13, 193,418,189]
  Mean=1.0000, Std=0.4142, Autocorr=-0.357
```

**–í–ê–ñ–ù–û:** –§–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã —Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –ß–ò–°–õ–û–í–´–ú –ø–æ—Ä—è–¥–∫–æ–º!
- ‚ùå –ê–ª—Ñ–∞–≤–∏—Ç–Ω—ã–π: zeros_101246000 < zeros_14 (WRONG!)
- ‚úÖ –ß–∏—Å–ª–æ–≤–æ–π: zeros_14 < zeros_5000 < zeros_26000 (CORRECT!)

---

## üîÑ EXPERIMENT WORKFLOW

### –ó–∞–ø—É—Å–∫ –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (E5, E6, etc.)

**–®–∞–≥ 1: –°–æ–∑–¥–∞–π —Ä–∞–±–æ—á—É—é –ø–∞–ø–∫—É**
```bash
mkdir -p out/E5_experiment_name
```

**–®–∞–≥ 2: –ó–∞–ø—É—Å—Ç–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É**
```bash
python src/train_mdn_postfix.py \
  --data-dir data/continuous_2M \
  --out-dir out/E5_experiment_name \
  --seed 7 \
  [–Ω–æ–≤—ã–µ —Ñ–ª–∞–≥–∏] \
  --batch-size 512 --use-amp
```

**–®–∞–≥ 3: –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è ‚Äî —Ä–∞—Å–∫–ª–∞–¥—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**
```bash
# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å ‚Üí checkpoints/
cp out/E5_experiment_name/best.pt checkpoints/E5_best.pt

# –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ ‚Üí results/
mkdir -p results/E5
python src/diagnose_memory_postfix.py \
  --ckpt checkpoints/E5_best.pt \
  --data-dir data/continuous_2M \
  --output-dir results/E5

# –û–±–Ω–æ–≤–∏ docs/PROJECT_MAP.md —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏!
```

**–®–∞–≥ 4: Cleanup –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤**
```bash
# out/ –≤ gitignore ‚Äî –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –∏–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ
rm -rf out/E5_experiment_name/ckpt_*.pt  # —É–¥–∞–ª–∏—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ
```

---

## üìÅ I/O CONVENTIONS

### Naming Rules
```
Checkpoints:  E{N}_{description}_best.pt
              E4_s7_best.pt, E5_ortho_best.pt

Results:      results/E{N}/
              results/E4_s7/postfix_diagnostics.jsonl

Logs:         out/E{N}_{name}/train.log (temporary)
```

### Input Paths (–ù–ò–ö–û–ì–î–ê –Ω–µ –º–µ–Ω—è–π!)
```python
DATA_DIR = "data/continuous_2M"
TRAIN_PATH = "data/continuous_2M/train.pt"  # (7035, 256)
VAL_PATH = "data/continuous_2M/val.pt"      # (781, 256)
```

### Output Paths
```python
# Temporary (during training):
OUT_DIR = f"out/{experiment_name}"

# Permanent (after training):
CHECKPOINT = f"checkpoints/{experiment_name}_best.pt"
RESULTS = f"results/{experiment_name}/"
```

---

## üìù LOGGING RULES (–ö–†–ò–¢–ò–ß–ù–û!)

### –ü—Ä–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å:

**–í –Ω–∞—á–∞–ª–µ:**
- GPU name, VRAM
- batch_size
- Experiment config (flags)

**–ö–∞–∂–¥—ã–π eval:**
```
Step 1000/20000 | val_nll=0.358 (best=0.358) | 5.8 steps/s | ETA: 55m | elapsed: 2.9m
```

**–í –∫–æ–Ω—Ü–µ:**
- Total time, steps/sec
- Best NLL achieved
- Cost estimate ($/hr √ó time)

---

## üìã –ü–û–°–õ–ï –ö–ê–ñ–î–û–ì–û –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê

### Checklist:
- [ ] –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å `best.pt` –≤ `checkpoints/`
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –≤ `results/`
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `docs/PROJECT_MAP.md`:
  - Experiments Timeline
  - E{N} Results table
  - Key Insights Log
- [ ] Commit & push

---

## üèóÔ∏è Repository Structure

```
nanoGpt_RH/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/                      # MAIN CODE
‚îÇ   ‚îú‚îÄ‚îÄ train_mdn.py             # Base SpacingMDN (MDNConfig)
‚îÇ   ‚îú‚îÄ‚îÄ train_mdn_postfix.py     # ‚≠ê E4 training (ID-Detox, aux-loss)
‚îÇ   ‚îú‚îÄ‚îÄ train_mdn_memory.py      # PREFIX memory (deprecated)
‚îÇ   ‚îú‚îÄ‚îÄ eval_mdn.py              # Evaluation (NLL, CRPS, PIT)
‚îÇ   ‚îú‚îÄ‚îÄ diagnose_memory.py       # PREFIX diagnostics
‚îÇ   ‚îî‚îÄ‚îÄ diagnose_memory_postfix.py # ‚≠ê POSTFIX diagnostics (A-K)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ scripts/                  # UTILITIES
‚îÇ   ‚îú‚îÄ‚îÄ prepare_continuous_2M.py # Unfolding zeros ‚Üí spacings
‚îÇ   ‚îú‚îÄ‚îÄ prepare_zeros.py         # Raw zeros processing
‚îÇ   ‚îú‚îÄ‚îÄ prepare_primes.py        # Prime gaps dataset
‚îÇ   ‚îî‚îÄ‚îÄ runpod_setup.sh          # RunPod setup script
‚îÇ
‚îú‚îÄ‚îÄ üìÅ checkpoints/              # TRAINED MODELS (Git LFS)
‚îÇ   ‚îú‚îÄ‚îÄ E0_baseline_best.pt      # SpacingMDN no memory
‚îÇ   ‚îú‚îÄ‚îÄ E1_prefix_best.pt        # PREFIX (decorative)
‚îÇ   ‚îú‚îÄ‚îÄ E2_prefix_best.pt        # PREFIX (seed variance)
‚îÇ   ‚îú‚îÄ‚îÄ E3_postfix_s1337_best.pt # POSTFIX (ID-crutch)
‚îÇ   ‚îú‚îÄ‚îÄ E4_s7_best.pt            # ‚≠ê BEST! NLL=0.1942
‚îÇ   ‚îî‚îÄ‚îÄ E4_s1337_best.pt         # E4 (stuck seed)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/                     # DATASET
‚îÇ   ‚îî‚îÄ‚îÄ continuous_2M/           # Main dataset
‚îÇ       ‚îú‚îÄ‚îÄ train.pt             # (7035, 256)
‚îÇ       ‚îú‚îÄ‚îÄ val.pt               # (781, 256)
‚îÇ       ‚îî‚îÄ‚îÄ meta.pt
‚îÇ
‚îú‚îÄ‚îÄ üìÅ docs/                     # DOCUMENTATION
‚îÇ   ‚îú‚îÄ‚îÄ PROJECT_MAP.md           # ‚≠ê MAIN PROJECT MAP
‚îÇ   ‚îú‚îÄ‚îÄ E4_SPEC.md               # E4 specification
‚îÇ   ‚îî‚îÄ‚îÄ runpod_specs.md          # GPU comparison
‚îÇ
‚îú‚îÄ‚îÄ üìÅ results/                  # DIAGNOSTICS OUTPUT
‚îÇ   ‚îî‚îÄ‚îÄ E4_s7/
‚îÇ       ‚îú‚îÄ‚îÄ postfix_diagnostics.jsonl
‚îÇ       ‚îî‚îÄ‚îÄ postfix_diagnostics.png
‚îÇ
‚îú‚îÄ‚îÄ üìÅ out/                      # TEMPORARY (gitignored)
‚îÇ
‚îî‚îÄ‚îÄ üìÅ archive/                  # OLD CODE (gitignored)
```

---

## üñ•Ô∏è RunPod Quick Start

### ‚ö†Ô∏è SSH Setup (–í–ê–ñ–ù–û! –û–¥–∏–Ω —Ä–∞–∑ –Ω–∞–≤—Å–µ–≥–¥–∞)

**–ü—Ä–æ–±–ª–µ–º–∞:** RunPod –ù–ï —á–∏—Ç–∞–µ—Ç SSH –∫–ª—é—á–∏ —Å —Ç–≤–æ–µ–≥–æ –∫–æ–º–ø–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!
–ö–ª—é—á–∏ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ RunPod Account Settings –ó–ê–†–ê–ù–ï–ï.

**–†–µ—à–µ–Ω–∏–µ (–æ–¥–∏–Ω —Ä–∞–∑):**
1. –°–∫–æ–ø–∏—Ä—É–π –ø—É–±–ª–∏—á–Ω—ã–π –∫–ª—é—á: `cat ~/.ssh/id_ed25519.pub`
2. –ò–¥–∏ –≤ [RunPod Settings ‚Üí SSH Keys](https://www.runpod.io/console/user/settings)
3. –î–æ–±–∞–≤—å –∫–ª—é—á
4. –í—Å–µ –ù–û–í–´–ï –ø–æ–¥—ã –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –ø–∞—Ä–æ–ª—è

**–ï—Å–ª–∏ –ø–æ–¥ —É–∂–µ —Å–æ–∑–¥–∞–Ω –±–µ–∑ –∫–ª—é—á–∞** ‚Äî –¥–æ–±–∞–≤—å —á–µ—Ä–µ–∑ Web Terminal:
```bash
mkdir -p ~/.ssh && chmod 700 ~/.ssh && \
echo "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIDmeQP05UiH0tXgAhL+Nx6nJZTgon9G63shnpUY9qL+2 emalam@example.com" \
>> ~/.ssh/authorized_keys && chmod 600 ~/.ssh/authorized_keys
```

**–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –ø–æ SSH:**
```bash
# –í–∞—Ä–∏–∞–Ω—Ç 1: —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ (–±–µ–∑ SCP/SFTP)
ssh vjex2o62haxaew-644114f5@ssh.runpod.io -i ~/.ssh/id_ed25519

# –í–∞—Ä–∏–∞–Ω—Ç 2: –ø—Ä—è–º–æ–π TCP (—Å SCP/SFTP)
ssh root@<IP> -p <PORT> -i ~/.ssh/id_ed25519
```

–ò—Å—Ç–æ—á–Ω–∏–∫: [RunPod SSH Docs](https://docs.runpod.io/pods/configuration/use-ssh)

---

### üöÄ SCP File Transfer (–ò–°–ü–û–õ–¨–ó–£–ï–ú!)

**–ù–∞—Ç–∏–≤–Ω—ã–π SCP** ‚Äî –±—ã—Å—Ç—Ä–æ, –Ω–∞–¥—ë–∂–Ω–æ, –Ω–µ —Ç–æ—Ä–º–æ–∑–∏—Ç Mac.
SSHFS/macFUSE —É–¥–∞–ª–µ–Ω—ã ‚Äî –æ–Ω–∏ –≥—Ä—É–∑–∏–ª–∏ —Å–∏—Å—Ç–µ–º—É.

**Upload –Ω–∞ RunPod:**
```bash
# –û–¥–∏–Ω —Ñ–∞–π–ª
scp -P <PORT> -i ~/.ssh/id_ed25519 local_file.py root@<IP>:/workspace/pair-correlation/

# –ù–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤
scp -P <PORT> -i ~/.ssh/id_ed25519 scripts/*.py root@<IP>:/workspace/pair-correlation/scripts/

# –¶–µ–ª–∞—è –ø–∞–ø–∫–∞
scp -rP <PORT> -i ~/.ssh/id_ed25519 src/ root@<IP>:/workspace/pair-correlation/src/
```

**Download —Å RunPod:**
```bash
# –û–¥–∏–Ω —Ñ–∞–π–ª
scp -P <PORT> -i ~/.ssh/id_ed25519 root@<IP>:/workspace/pair-correlation/results/file.json ./

# –ß–µ–∫–ø–æ–∏–Ω—Ç
scp -P <PORT> -i ~/.ssh/id_ed25519 root@<IP>:/workspace/pair-correlation/out/best.pt checkpoints/

# –¶–µ–ª–∞—è –ø–∞–ø–∫–∞
scp -rP <PORT> -i ~/.ssh/id_ed25519 root@<IP>:/workspace/pair-correlation/results/ ./results/
```

**–ü—Ä–∏–º–µ—Ä —Å —Ç–µ–∫—É—â–∏–º –ø–æ–¥–æ–º:**
```bash
# Upload —Å–∫—Ä–∏–ø—Ç–∞
scp -P 22066 scripts/symbolic_distillation.py root@69.30.85.23:/workspace/pair-correlation/scripts/

# Download —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
scp -P 22066 root@69.30.85.23:/workspace/pair-correlation/results/*.json ./results/
```

---

### üì¶ Package & Send (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)
```bash
tar czf runpod_package.tar.gz \
  src/train_mdn.py src/train_mdn_postfix.py \
  src/eval_mdn.py src/diagnose_memory_postfix.py \
  scripts/runpod_setup.sh data/continuous_2M

runpodctl send runpod_package.tar.gz
```

### On Pod
```bash
runpodctl receive <CODE> && tar xzf runpod_package.tar.gz

# Training
python src/train_mdn_postfix.py \
  --data-dir data/continuous_2M \
  --out-dir out/E5_experiment \
  --seed 7 \
  --slot-id-mode permute_per_batch \
  --use-aux-loss \
  --early-stop --patience 800 \
  --batch-size 512 --use-amp
```

### Download Results
```bash
# On pod:
tar czf results.tar.gz out/E5_experiment/ && runpodctl send results.tar.gz

# On Mac:
runpodctl receive <CODE>
tar xzf results.tar.gz
```

### GPU Selection
```
BEST:    RTX 6000 Ada @ $0.77/hr (48GB, –¥–µ—à–µ–≤–ª–µ –∏ –±—ã—Å—Ç—Ä–µ–µ L40S!)
         ‚Ü≥ Low availability, –Ω–æ —Å—Ç–æ–∏—Ç –ø–æ–¥–æ–∂–¥–∞—Ç—å
DEFAULT: L40S @ $0.86/hr (48GB, ML-optimized, high availability)
BUDGET:  A40 @ $0.40/hr (48GB, best $/perf)
FAST:    H100 @ $2.69/hr (80GB, 2.5x speed)
```

**Benchmark (3 parallel, batch 512):**
- RTX 6000 Ada: ~2.0 steps/sec each
- L40S: ~1.6 steps/sec each
- RTX 6000 Ada wins: –¥–µ—à–µ–≤–ª–µ ($0.77 vs $0.86) –ò –±—ã—Å—Ç—Ä–µ–µ!

---

## ‚öôÔ∏è E4 Training Flags Reference

```bash
python src/train_mdn_postfix.py \
  --data-dir data/continuous_2M \      # INPUT: always this!
  --out-dir out/experiment_name \      # OUTPUT: temporary
  --seed 7 \                           # Seed (7 worked best)
  --slot-id-mode permute_per_batch \   # ID-detox (E4)
  --content-mode normal \              # or zeroed
  --use-aux-loss \                     # Q3-proxy supervision
  --early-stop --patience 800 \        # Early stopping
  --batch-size 512 \                   # 512 for 48GB GPU
  --use-amp                            # Mixed precision
```

---

## üî¨ Diagnostics Metrics

### A-K –º–µ—Ç—Ä–∏–∫–∏ –≤ diagnose_memory_postfix.py:
```
A) Ablation Œî      ‚Äî –≤–∞–∂–Ω–æ—Å—Ç—å —Å–ª–æ—Ç–∞ (—Ü–µ–ª—å: >0.02)
B) Slot Similarity ‚Äî –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ (—Ü–µ–ª—å: <0.5)
C) Grad Correlation‚Äî –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (—Ü–µ–ª—å: <0.7)
D) Readout Weights ‚Äî –≤–µ—Å–∞ —á—Ç–µ–Ω–∏—è (—Ü–µ–ª—å: uniform)
E) Effect Entropy  ‚Äî —ç–Ω—Ç—Ä–æ–ø–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∞ (—Ü–µ–ª—å: >1.5)
F) Slot Norms      ‚Äî –Ω–æ—Ä–º—ã —Å–ª–æ—Ç–æ–≤
G) Rollout Drift   ‚Äî —Ä–æ—Å—Ç –æ—à–∏–±–∫–∏ (—Ü–µ–ª—å: slope<0.5)
H) Cross-Block CV  ‚Äî distribution shift (—Ü–µ–ª—å: <0.3)
I) Attention CoM   ‚Äî center of mass (—Ü–µ–ª—å: std>10)
J) Permutation Inc ‚Äî ID-reliance (—Ü–µ–ª—å: <10%)
K) Gradient Rank   ‚Äî effective rank (—Ü–µ–ª—å: >50%)
```

---

## üìä Experiments History

| ID | Architecture | Best NLL | Key Result |
|----|--------------|----------|------------|
| E0 | Baseline MDN | -0.25 | No memory |
| E1 | PREFIX Memory | -0.38 | Memory decorative |
| E2 | PREFIX Memory | -0.38 | Seed variance |
| E3 | POSTFIX Memory | 0.304 | ID-crutch detected |
| **E4** | **POSTFIX+ID-Detox** | **0.1942** | **ID-Detox works!** |

---

## ‚ùå COMMON MISTAKES (–Ω–µ –¥–µ–ª–∞–π!)

1. **–ù–µ –∑–∞–ø—É—Å–∫–∞–π –∏–∑ root –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –ø—É—Ç–µ–π!**
   ```bash
   # WRONG:
   python train_mdn_postfix.py

   # RIGHT:
   python src/train_mdn_postfix.py --data-dir data/continuous_2M
   ```

2. **–ù–µ –∑–∞–±—ã–≤–∞–π --out-dir!**
   - –ë–µ–∑ –Ω–µ–≥–æ output –ø–æ–π–¥–µ—Ç –≤ —Å–ª—É—á–∞–π–Ω–æ–µ –º–µ—Å—Ç–æ

3. **–ù–µ –∫–æ–º–º–∏—Ç—å out/ !**
   - –¢–æ–ª—å–∫–æ checkpoints/ –∏ results/

4. **–ü–æ—Å–ª–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ ‚Äî –æ–±–Ω–æ–≤–∏ docs/PROJECT_MAP.md!**

---

## üéì Project Overview

**nanoGPT_RH** ‚Äî Neural telescope for Riemann Hypothesis spectral analysis.

**Goal:** Train transformer on 2M unfolded zeta zeros to:
1. Learn GUE-like spacing distribution
2. Extract operator/kernel via attention
3. Compare with Q3 formal structures

**Architecture:** SpacingMDN + POSTFIX Memory Bank
- Memory slots AFTER data (bottleneck readout)
- ID-Detox prevents slot-ID cheating
- Q3-proxy aux loss for supervision

**Data:** Unfolded spacings with mean ‚âà 1
```
s_n = Œî_n * log(Œ≥_n) / (2œÄ)
```

---

*Last updated: 2026-01-02*
