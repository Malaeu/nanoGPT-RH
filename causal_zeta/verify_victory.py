#!/usr/bin/env python3
"""
Operation Reality Check: –ü–æ–ø—ã—Ç–∫–∞ –£–ù–ò–ß–¢–û–ñ–ò–¢–¨ —Ä–µ–∑—É–ª—å—Ç–∞—Ç +78% SFF.

–ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–∂–∏–≤–µ—Ç ‚Äî –æ–Ω –Ω–∞—Å—Ç–æ—è—â–∏–π.
–ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –º—ã –Ω–∞—à–ª–∏ –±–∞–≥.

3 —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∞:
1. PLACEBO CONTROL - —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º vs —É–º–Ω–∞—è –ø–∞–º—è—Ç—å
2. LEAKAGE CHECK - –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–ø–∏–ø–∞—Å—Ç warmup –¥–∞–Ω–Ω—ã—Ö
3. STABILITY - 100 —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏

Usage:
    python -m causal_zeta.verify_victory --checkpoint out/best.pt
"""

import argparse
import sys
from pathlib import Path
import numpy as np
import torch
import torch.nn.functional as F
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import track
from scipy import stats

sys.path.insert(0, str(Path(__file__).parent.parent))

from model.gpt import SpacingGPT

console = Console()


def compute_sff(spacings: np.ndarray, tau_values: np.ndarray = None) -> dict:
    """Compute Spectral Form Factor."""
    u = np.concatenate([[0], np.cumsum(spacings)])
    N = len(u)

    if tau_values is None:
        tau_values = np.logspace(-1, np.log10(2*np.pi), 100)

    K_values = np.zeros(len(tau_values))
    for i, tau in enumerate(tau_values):
        phases = np.exp(1j * tau * u)
        K_values[i] = np.abs(np.sum(phases))**2 / N

    plateau_mask = tau_values > 4.0
    plateau = np.mean(K_values[plateau_mask]) if np.sum(plateau_mask) > 0 else K_values[-1]

    ramp_mask = (tau_values >= 0.5) & (tau_values <= 3.0)
    if np.sum(ramp_mask) > 2:
        tau_ramp = tau_values[ramp_mask]
        K_ramp = K_values[ramp_mask]
        slope, _ = np.polyfit(tau_ramp, K_ramp, 1)
    else:
        slope = 0.0

    return {"tau": tau_values, "K": K_values, "plateau": plateau, "ramp_slope": slope, "N": N}


class ElephantGenerator:
    """–£–º–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å –ø–∞–º—è—Ç—å—é (–æ—Ä–∏–≥–∏–Ω–∞–ª)."""

    def __init__(self, model: SpacingGPT, bin_centers: np.ndarray, device):
        self.model = model
        self.bin_centers = bin_centers
        self.device = device
        self.config = model.config
        self.memory_state = None
        self.memory_alpha = 0.5
        self.warmup_tokens = None  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É—Ç–µ—á–∫–∏

    def warmup(self, tokens: torch.Tensor, n_windows: int = 50):
        if tokens.dim() == 1:
            tokens = tokens.unsqueeze(0)

        self.memory_state = torch.zeros(1, 1, self.config.n_embd, device=self.device)
        self.warmup_tokens = tokens.cpu().numpy().flatten()  # –°–û–•–†–ê–ù–Ø–ï–ú!

        seq_len = self.config.seq_len
        total_tokens = tokens.shape[1]

        windows_processed = 0
        for start in range(0, total_tokens - seq_len, seq_len):
            if windows_processed >= n_windows:
                break
            window = tokens[:, start:start+seq_len].to(self.device)
            hidden_states = self.model.get_hidden_states(window)
            summary = hidden_states[-1][:, -1:, :]
            self.memory_state = self.memory_alpha * self.memory_state + (1 - self.memory_alpha) * summary
            windows_processed += 1

    def generate_with_memory(self, context: torch.Tensor, n_tokens: int, temperature: float = 1.0) -> torch.Tensor:
        seq_len = self.config.seq_len
        generated = context.clone()

        for _ in range(n_tokens):
            idx_cond = generated[:, -seq_len:] if generated.shape[1] > seq_len else generated
            logits, _ = self.model(idx_cond)
            logits = logits[:, -1, :] / temperature

            # MEMORY INJECTION
            if self.memory_state is not None:
                mem_flat = self.memory_state.squeeze()
                mem_bias = torch.matmul(mem_flat, self.model.lm_head.weight.T)
                logits = logits + 0.1 * mem_bias.unsqueeze(0)

            probs = F.softmax(logits, dim=-1)
            idx_next = torch.multinomial(probs, num_samples=1)
            generated = torch.cat([generated, idx_next], dim=1)

            # Update memory periodically
            if generated.shape[1] % seq_len == 0:
                window = generated[:, -seq_len:]
                hidden_states = self.model.get_hidden_states(window)
                summary = hidden_states[-1][:, -1:, :]
                self.memory_state = self.memory_alpha * self.memory_state + (1 - self.memory_alpha) * summary

        return generated[:, context.shape[1]:]


class PlaceboGenerator:
    """
    –ü–õ–ê–¶–ï–ë–û: –í–º–µ—Å—Ç–æ —É–º–Ω–æ–π –ø–∞–º—è—Ç–∏ ‚Äî –°–õ–£–ß–ê–ô–ù–´–ô –®–£–ú —Ç–æ–π –∂–µ –∞–º–ø–ª–∏—Ç—É–¥—ã.
    –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–∞–∫–æ–π –∂–µ ‚Äî –∑–Ω–∞—á–∏—Ç –¥–µ–ª–æ –Ω–µ –≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∞ –≤ —à—É–º–µ.
    """

    def __init__(self, model: SpacingGPT, bin_centers: np.ndarray, device):
        self.model = model
        self.bin_centers = bin_centers
        self.device = device
        self.config = model.config
        self.noise_scale = None  # –ë—É–¥–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∞ –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ Elephant

    def calibrate_noise(self, elephant_memory_norm: float):
        """–ö–∞–ª–∏–±—Ä–æ–≤–∞—Ç—å —à—É–º –ø–æ –Ω–æ—Ä–º–µ —Ä–µ–∞–ª—å–Ω–æ–π –ø–∞–º—è—Ç–∏."""
        self.noise_scale = elephant_memory_norm

    def generate_with_noise(self, context: torch.Tensor, n_tokens: int, temperature: float = 1.0) -> torch.Tensor:
        seq_len = self.config.seq_len
        generated = context.clone()
        n_embd = self.config.n_embd

        for _ in range(n_tokens):
            idx_cond = generated[:, -seq_len:] if generated.shape[1] > seq_len else generated
            logits, _ = self.model(idx_cond)
            logits = logits[:, -1, :] / temperature

            # RANDOM NOISE –≤–º–µ—Å—Ç–æ —É–º–Ω–æ–π –ø–∞–º—è—Ç–∏!
            random_mem = torch.randn(n_embd, device=self.device)
            if self.noise_scale is not None:
                random_mem = random_mem * self.noise_scale / torch.norm(random_mem)
            noise_bias = torch.matmul(random_mem, self.model.lm_head.weight.T)
            logits = logits + 0.1 * noise_bias.unsqueeze(0)

            probs = F.softmax(logits, dim=-1)
            idx_next = torch.multinomial(probs, num_samples=1)
            generated = torch.cat([generated, idx_next], dim=1)

        return generated[:, context.shape[1]:]


class AmnesiacGenerator:
    """–ë–∞–∑–æ–≤—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –±–µ–∑ –ø–∞–º—è—Ç–∏ (–∫–æ–Ω—Ç—Ä–æ–ª—å)."""

    def __init__(self, model: SpacingGPT, bin_centers: np.ndarray, device):
        self.model = model
        self.bin_centers = bin_centers
        self.device = device
        self.config = model.config

    def generate(self, context: torch.Tensor, n_tokens: int, temperature: float = 1.0) -> torch.Tensor:
        seq_len = self.config.seq_len
        generated = context.clone()

        for _ in range(n_tokens):
            idx_cond = generated[:, -seq_len:] if generated.shape[1] > seq_len else generated
            logits, _ = self.model(idx_cond)
            logits = logits[:, -1, :] / temperature
            probs = F.softmax(logits, dim=-1)
            idx_next = torch.multinomial(probs, num_samples=1)
            generated = torch.cat([generated, idx_next], dim=1)

        return generated[:, context.shape[1]:]


def test_placebo_control(model, val_data, bin_centers, args, device) -> dict:
    """
    –¢–ï–°–¢ 1: PLACEBO CONTROL
    Elephant vs Random Noise ‚Äî –∫—Ç–æ –ø–æ–±–µ–¥–∏—Ç?
    """
    console.print(Panel.fit("[bold red]–¢–ï–°–¢ 1: PLACEBO CONTROL[/]\n–£–º–Ω–∞—è –ø–∞–º—è—Ç—å vs –°–ª—É—á–∞–π–Ω—ã–π —à—É–º", title="üß™"))

    n_traj = args.n_traj
    traj_len = args.traj_len
    context_len = args.context_len

    contexts = []
    for i in range(min(n_traj, len(val_data))):
        ctx = val_data[i:i+1, :context_len].to(device)
        contexts.append(ctx)

    # Elephant (—É–º–Ω—ã–π)
    console.print("\n[blue]üêò Running Elephant (Smart Memory)...[/]")
    elephant = ElephantGenerator(model, bin_centers, device)
    warmup_data = val_data[:args.warmup_windows].reshape(-1)
    elephant.warmup(warmup_data, n_windows=args.warmup_windows)

    elephant_memory_norm = torch.norm(elephant.memory_state).item()
    console.print(f"  Memory norm: {elephant_memory_norm:.4f}")

    elephant_spacings = []
    for ctx in track(contexts, description="Elephant generating"):
        with torch.no_grad():
            generated = elephant.generate_with_memory(ctx, traj_len, temperature=1.0)
            tokens = generated[0].cpu().numpy()
            spacings = bin_centers[tokens]
            elephant_spacings.extend(spacings)

    sff_elephant = compute_sff(np.array(elephant_spacings))

    # Placebo (—à—É–º)
    console.print("\n[yellow]üé≤ Running Placebo (Random Noise)...[/]")
    placebo = PlaceboGenerator(model, bin_centers, device)
    placebo.calibrate_noise(elephant_memory_norm)

    placebo_spacings = []
    for ctx in track(contexts, description="Placebo generating"):
        with torch.no_grad():
            generated = placebo.generate_with_noise(ctx, traj_len, temperature=1.0)
            tokens = generated[0].cpu().numpy()
            spacings = bin_centers[tokens]
            placebo_spacings.extend(spacings)

    sff_placebo = compute_sff(np.array(placebo_spacings))

    # Amnesiac (–∫–æ–Ω—Ç—Ä–æ–ª—å)
    console.print("\n[red]üî¥ Running Amnesiac (No intervention)...[/]")
    amnesiac = AmnesiacGenerator(model, bin_centers, device)

    amnesiac_spacings = []
    for ctx in track(contexts, description="Amnesiac generating"):
        with torch.no_grad():
            generated = amnesiac.generate(ctx, traj_len, temperature=1.0)
            tokens = generated[0].cpu().numpy()
            spacings = bin_centers[tokens]
            amnesiac_spacings.extend(spacings)

    sff_amnesiac = compute_sff(np.array(amnesiac_spacings))

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    table = Table(title="PLACEBO CONTROL RESULTS")
    table.add_column("Generator", style="bold")
    table.add_column("SFF Plateau", justify="right")
    table.add_column("vs Amnesiac", justify="right")

    table.add_row("üî¥ Amnesiac (baseline)", f"{sff_amnesiac['plateau']:.4f}", "1.00x")
    table.add_row("üé≤ Placebo (noise)", f"{sff_placebo['plateau']:.4f}",
                  f"{sff_placebo['plateau']/sff_amnesiac['plateau']:.2f}x")
    table.add_row("üêò Elephant (smart)", f"{sff_elephant['plateau']:.4f}",
                  f"{sff_elephant['plateau']/sff_amnesiac['plateau']:.2f}x")

    console.print(table)

    # –í–µ—Ä–¥–∏–∫—Ç
    elephant_vs_placebo = sff_elephant['plateau'] / sff_placebo['plateau'] if sff_placebo['plateau'] > 0 else 0
    if elephant_vs_placebo > 1.2:
        verdict = "‚úÖ PASS: Elephant > Placebo (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç!)"
        status = "PASS"
    elif elephant_vs_placebo > 1.05:
        verdict = "‚ö†Ô∏è MARGINAL: Elephant –Ω–µ–º–Ω–æ–≥–æ –ª—É—á—à–µ Placebo"
        status = "MARGINAL"
    else:
        verdict = "‚ùå FAIL: Elephant ‚âà Placebo (—ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —à—É–º!)"
        status = "FAIL"

    console.print(f"\n[bold]{verdict}[/]")
    console.print(f"Elephant/Placebo ratio: {elephant_vs_placebo:.2f}x")

    return {
        "status": status,
        "elephant_plateau": sff_elephant['plateau'],
        "placebo_plateau": sff_placebo['plateau'],
        "amnesiac_plateau": sff_amnesiac['plateau'],
        "elephant_vs_placebo": elephant_vs_placebo,
        "elephant_warmup_tokens": elephant.warmup_tokens,
    }


def test_leakage_check(elephant_warmup_tokens: np.ndarray, generated_tokens: np.ndarray) -> dict:
    """
    –¢–ï–°–¢ 2: LEAKAGE CHECK
    –°—Ä–∞–≤–Ω–∏—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã —Å warmup –¥–∞–Ω–Ω—ã–º–∏.
    """
    console.print(Panel.fit("[bold red]–¢–ï–°–¢ 2: LEAKAGE CHECK[/]\n–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–ø–∏–ø–∞—Å—Ç warmup –¥–∞–Ω–Ω—ã—Ö", title="üîç"))

    warmup_set = set(elephant_warmup_tokens.tolist())
    generated_set = set(generated_tokens.tolist())

    # –¢–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (sliding window)
    warmup_str = ''.join(map(str, elephant_warmup_tokens[:10000]))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º
    gen_str = ''.join(map(str, generated_tokens[:10000]))

    # –ò—â–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–æ–¥—Å—Ç—Ä–æ–∫–∏ –¥–ª–∏–Ω–æ–π >= 10
    overlap_count = 0
    window_size = 10
    for i in range(len(gen_str) - window_size):
        substr = gen_str[i:i+window_size]
        if substr in warmup_str:
            overlap_count += 1

    overlap_pct = overlap_count / max(1, len(gen_str) - window_size) * 100

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤
    warmup_hist = np.bincount(elephant_warmup_tokens, minlength=256)
    gen_hist = np.bincount(generated_tokens, minlength=256)

    # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π (—ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ —á—Ç–æ –≤—ã—Å–æ–∫–∞—è ‚Äî same domain)
    distribution_corr = np.corrcoef(warmup_hist, gen_hist)[0, 1]

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    table = Table(title="LEAKAGE CHECK RESULTS")
    table.add_column("Metric", style="cyan")
    table.add_column("Value", justify="right")
    table.add_column("Threshold", justify="right")
    table.add_column("Status", justify="center")

    table.add_row(
        "Sequence overlap (10-grams)",
        f"{overlap_pct:.2f}%",
        "< 5%",
        "‚úÖ" if overlap_pct < 5 else "‚ùå"
    )
    table.add_row(
        "Distribution correlation",
        f"{distribution_corr:.4f}",
        "< 0.95 (expected high)",
        "‚úÖ" if distribution_corr < 0.99 else "‚ö†Ô∏è"
    )

    console.print(table)

    if overlap_pct < 5:
        verdict = "‚úÖ PASS: –ù–µ—Ç —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö"
        status = "PASS"
    elif overlap_pct < 20:
        verdict = "‚ö†Ô∏è WARNING: –ù–µ–±–æ–ª—å—à–æ–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ, –ø—Ä–æ–≤–µ—Ä–∏—Ç—å"
        status = "WARNING"
    else:
        verdict = "‚ùå FAIL: –ú–æ–¥–µ–ª—å –∫–æ–ø–∏–ø–∞—Å—Ç–∏—Ç warmup!"
        status = "FAIL"

    console.print(f"\n[bold]{verdict}[/]")

    return {
        "status": status,
        "overlap_pct": overlap_pct,
        "distribution_corr": distribution_corr,
    }


def test_stability(model, val_data, bin_centers, args, device) -> dict:
    """
    –¢–ï–°–¢ 3: STABILITY
    100 —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏.
    """
    console.print(Panel.fit("[bold red]–¢–ï–°–¢ 3: STABILITY[/]\n100 —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏", title="üìä"))

    n_traj = 100  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ 100
    traj_len = args.traj_len
    context_len = args.context_len

    contexts = []
    for i in range(min(n_traj, len(val_data))):
        ctx = val_data[i:i+1, :context_len].to(device)
        contexts.append(ctx)

    # Elephant
    elephant = ElephantGenerator(model, bin_centers, device)
    warmup_data = val_data[:args.warmup_windows].reshape(-1)
    elephant.warmup(warmup_data, n_windows=args.warmup_windows)

    # –°–æ–±–∏—Ä–∞–µ–º plateau –¥–ª—è –∫–∞–∂–¥–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
    elephant_plateaus = []
    amnesiac_plateaus = []

    amnesiac = AmnesiacGenerator(model, bin_centers, device)

    console.print("\n[blue]Running 100 trajectories...[/]")
    for ctx in track(contexts, description="Generating"):
        with torch.no_grad():
            # Elephant
            gen_e = elephant.generate_with_memory(ctx, traj_len, temperature=1.0)
            tokens_e = gen_e[0].cpu().numpy()
            spacings_e = bin_centers[tokens_e]
            sff_e = compute_sff(spacings_e)
            elephant_plateaus.append(sff_e['plateau'])

            # Amnesiac
            gen_a = amnesiac.generate(ctx, traj_len, temperature=1.0)
            tokens_a = gen_a[0].cpu().numpy()
            spacings_a = bin_centers[tokens_a]
            sff_a = compute_sff(spacings_a)
            amnesiac_plateaus.append(sff_a['plateau'])

    elephant_plateaus = np.array(elephant_plateaus)
    amnesiac_plateaus = np.array(amnesiac_plateaus)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    e_mean, e_std = np.mean(elephant_plateaus), np.std(elephant_plateaus)
    a_mean, a_std = np.mean(amnesiac_plateaus), np.std(amnesiac_plateaus)

    # t-test
    t_stat, p_value = stats.ttest_ind(elephant_plateaus, amnesiac_plateaus)

    # Effect size (Cohen's d)
    pooled_std = np.sqrt((e_std**2 + a_std**2) / 2)
    cohens_d = (e_mean - a_mean) / pooled_std if pooled_std > 0 else 0

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    table = Table(title="STABILITY RESULTS (N=100)")
    table.add_column("Generator", style="bold")
    table.add_column("Mean Plateau", justify="right")
    table.add_column("Std", justify="right")
    table.add_column("95% CI", justify="right")

    e_ci = 1.96 * e_std / np.sqrt(len(elephant_plateaus))
    a_ci = 1.96 * a_std / np.sqrt(len(amnesiac_plateaus))

    table.add_row("üî¥ Amnesiac", f"{a_mean:.4f}", f"{a_std:.4f}", f"¬±{a_ci:.4f}")
    table.add_row("üêò Elephant", f"{e_mean:.4f}", f"{e_std:.4f}", f"¬±{e_ci:.4f}")

    console.print(table)

    console.print(f"\n[bold]Statistical Tests:[/]")
    console.print(f"  t-statistic: {t_stat:.4f}")
    console.print(f"  p-value: {p_value:.6f}")
    console.print(f"  Cohen's d: {cohens_d:.4f}")
    console.print(f"  Improvement: {(e_mean/a_mean - 1)*100:.1f}%")

    if p_value < 0.01 and cohens_d > 0.5:
        verdict = "‚úÖ PASS: –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ (p<0.01, d>0.5)"
        status = "PASS"
    elif p_value < 0.05:
        verdict = "‚ö†Ô∏è MARGINAL: –ó–Ω–∞—á–∏–º–æ, –Ω–æ —Å–ª–∞–±—ã–π —ç—Ñ—Ñ–µ–∫—Ç"
        status = "MARGINAL"
    else:
        verdict = "‚ùå FAIL: –ù–µ –∑–Ω–∞—á–∏–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏"
        status = "FAIL"

    console.print(f"\n[bold]{verdict}[/]")

    return {
        "status": status,
        "elephant_mean": e_mean,
        "elephant_std": e_std,
        "amnesiac_mean": a_mean,
        "amnesiac_std": a_std,
        "t_stat": t_stat,
        "p_value": p_value,
        "cohens_d": cohens_d,
        "improvement_pct": (e_mean/a_mean - 1)*100,
    }


def main():
    parser = argparse.ArgumentParser(description="Operation Reality Check")
    parser.add_argument("--checkpoint", type=str, default="out/best.pt")
    parser.add_argument("--data-dir", type=str, default="data")
    parser.add_argument("--n-traj", type=int, default=50, help="Trajectories for placebo test")
    parser.add_argument("--traj-len", type=int, default=512)
    parser.add_argument("--context-len", type=int, default=64)
    parser.add_argument("--warmup-windows", type=int, default=100)
    parser.add_argument("--seed", type=int, default=42)
    args = parser.parse_args()

    # Seed for reproducibility
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)

    console.print(Panel.fit(
        "[bold red]üî¨ OPERATION REALITY CHECK üî¨[/]\n\n"
        "–ü–æ–ø—ã—Ç–∫–∞ –£–ù–ò–ß–¢–û–ñ–ò–¢–¨ —Ä–µ–∑—É–ª—å—Ç–∞—Ç +78% SFF.\n"
        "–ï—Å–ª–∏ –≤—ã–∂–∏–≤–µ—Ç ‚Äî –æ–Ω –Ω–∞—Å—Ç–æ—è—â–∏–π.",
        title="–ñ–ï–°–¢–ö–ò–ô –ê–£–î–ò–¢"
    ))

    # Load model
    console.print(f"\n[cyan]Loading: {args.checkpoint}[/]")
    ckpt = torch.load(args.checkpoint, map_location="cpu", weights_only=False)
    config = ckpt["config"]
    model = SpacingGPT(config)
    model.load_state_dict(ckpt["model"])

    if torch.backends.mps.is_available():
        device = torch.device("mps")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
    else:
        device = torch.device("cpu")

    model = model.to(device)
    model.eval()
    console.print(f"[green]Model on {device}[/]")

    # Load data
    data_path = Path(args.data_dir)
    val_data = torch.load(data_path / "val.pt", weights_only=False)
    bin_centers = np.load(data_path / "bin_centers.npy")

    # =========================================================================
    # RUN ALL TESTS
    # =========================================================================

    results = {}

    # Test 1: Placebo Control
    console.print("\n" + "="*60)
    placebo_result = test_placebo_control(model, val_data, bin_centers, args, device)
    results["placebo"] = placebo_result

    # Collect generated tokens for leakage check
    elephant = ElephantGenerator(model, bin_centers, device)
    warmup_data = val_data[:args.warmup_windows].reshape(-1)
    elephant.warmup(warmup_data, n_windows=args.warmup_windows)

    generated_tokens = []
    for i in range(min(10, len(val_data))):
        ctx = val_data[i:i+1, :args.context_len].to(device)
        with torch.no_grad():
            gen = elephant.generate_with_memory(ctx, args.traj_len, temperature=1.0)
            generated_tokens.extend(gen[0].cpu().numpy().tolist())

    # Test 2: Leakage Check
    console.print("\n" + "="*60)
    leakage_result = test_leakage_check(
        placebo_result["elephant_warmup_tokens"],
        np.array(generated_tokens)
    )
    results["leakage"] = leakage_result

    # Test 3: Stability
    console.print("\n" + "="*60)
    stability_result = test_stability(model, val_data, bin_centers, args, device)
    results["stability"] = stability_result

    # =========================================================================
    # FINAL VERDICT
    # =========================================================================
    console.print("\n" + "="*60)
    console.print(Panel.fit("[bold]üèÜ FINAL REALITY CHECK VERDICT üèÜ[/]", title="–†–ï–ó–£–õ–¨–¢–ê–¢–´"))

    table = Table(title="Summary")
    table.add_column("Test", style="cyan")
    table.add_column("Status", justify="center")
    table.add_column("Key Metric", justify="right")

    table.add_row(
        "1. Placebo Control",
        "‚úÖ" if placebo_result["status"] == "PASS" else "‚ùå",
        f"Elephant/Placebo: {placebo_result['elephant_vs_placebo']:.2f}x"
    )
    table.add_row(
        "2. Leakage Check",
        "‚úÖ" if leakage_result["status"] == "PASS" else "‚ùå",
        f"Overlap: {leakage_result['overlap_pct']:.2f}%"
    )
    table.add_row(
        "3. Stability (N=100)",
        "‚úÖ" if stability_result["status"] == "PASS" else "‚ùå",
        f"p={stability_result['p_value']:.4f}, d={stability_result['cohens_d']:.2f}"
    )

    console.print(table)

    # Overall verdict
    passed = sum(1 for r in [placebo_result, leakage_result, stability_result] if r["status"] == "PASS")

    console.print("\n")
    if passed == 3:
        console.print(Panel.fit(
            "[bold green]üéâ –ü–û–ë–ï–î–ê –ü–û–î–¢–í–ï–†–ñ–î–ï–ù–ê! üéâ[/]\n\n"
            "–í—Å–µ 3 —Ç–µ—Å—Ç–∞ –ø—Ä–æ–π–¥–µ–Ω—ã.\n"
            "–†–µ–∑—É–ª—å—Ç–∞—Ç +78% SFF ‚Äî –ù–ê–°–¢–û–Ø–©–ò–ô!\n\n"
            "Memory –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç long-range structure.",
            title="‚úÖ VERIFIED"
        ))
    elif passed >= 2:
        console.print(Panel.fit(
            "[bold yellow]‚ö†Ô∏è –ß–ê–°–¢–ò–ß–ù–ê–Ø –ü–û–ë–ï–î–ê ‚ö†Ô∏è[/]\n\n"
            f"–ü—Ä–æ–π–¥–µ–Ω–æ {passed}/3 —Ç–µ—Å—Ç–æ–≤.\n"
            "–†–µ–∑—É–ª—å—Ç–∞—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ –Ω–∞—Å—Ç–æ—è—â–∏–π, –Ω–æ –Ω—É–∂–Ω–∞ –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å.",
            title="‚ö†Ô∏è NEEDS REVIEW"
        ))
    else:
        console.print(Panel.fit(
            "[bold red]‚ùå –†–ï–ó–£–õ–¨–¢–ê–¢ –£–ù–ò–ß–¢–û–ñ–ï–ù ‚ùå[/]\n\n"
            f"–ü—Ä–æ–π–¥–µ–Ω–æ —Ç–æ–ª—å–∫–æ {passed}/3 —Ç–µ—Å—Ç–æ–≤.\n"
            "–ü–æ–±–µ–¥–∞ –±—ã–ª–∞ –∏–ª–ª—é–∑–∏–µ–π. –ò—â–µ–º –±–∞–≥.",
            title="‚ùå DEBUNKED"
        ))

    return results


if __name__ == "__main__":
    main()
